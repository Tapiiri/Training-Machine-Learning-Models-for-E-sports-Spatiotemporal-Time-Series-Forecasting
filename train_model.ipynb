{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils.get_or_create_combined_database import get_or_create_combined_database\n",
    "from utils.create_sequences_in_batches import calculate_sequences_in_batches\n",
    "from utils.compare_models import compare_models\n",
    "from utils.get_data import clear_cache, fetch_data_batches\n",
    "from utils.recreate_cleaned_data import recreate_cleaned_data\n",
    "\n",
    "from utils.create_sequences_in_batches import create_sequences_from_database_rows\n",
    "from utils.plot_prediction_on_plot import plot_prediction_on_plot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from constants import DB_columns\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(verbose=True, override=True)\n",
    "\n",
    "RECREATE_CLEANED_DATA = False\n",
    "\n",
    "zoom_range = ((75, 14350), (75, 14350))\n",
    "normalized_zoom_range = ((0, 1), (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 database files in the folder specified by DATABASE_FOLDER\n",
      "Found combined database /u/23/tarpill1/unix/Documents/combined2.db\n"
     ]
    }
   ],
   "source": [
    "database_folder = os.getenv(\"DATABASE_FOLDER\")\n",
    "\n",
    "database_file = get_or_create_combined_database(database_folder)\n",
    "\n",
    "table_name = \"champs_cleaned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RECREATE_CLEANED_DATA:\n",
    "    recreate_cleaned_data(database_file, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mordekaiser',\n",
       "  604.0,\n",
       "  612.0,\n",
       "  5.5419455,\n",
       "  645.0,\n",
       "  100,\n",
       "  2841236401,\n",
       "  '2841236401_100_Mordekaiser',\n",
       "  0.040266666666666666,\n",
       "  0.0408,\n",
       "  0.03078858611111111),\n",
       " ('Viego',\n",
       "  786.0,\n",
       "  436.0,\n",
       "  5.5419455,\n",
       "  630.0,\n",
       "  100,\n",
       "  2841236401,\n",
       "  '2841236401_100_Viego',\n",
       "  0.0524,\n",
       "  0.029066666666666668,\n",
       "  0.03078858611111111),\n",
       " ('Riven',\n",
       "  364.0,\n",
       "  136.0,\n",
       "  5.5419455,\n",
       "  745.0,\n",
       "  100,\n",
       "  2841236401,\n",
       "  '2841236401_100_Riven',\n",
       "  0.024266666666666666,\n",
       "  0.009066666666666667,\n",
       "  0.03078858611111111),\n",
       " ('Ezreal',\n",
       "  132.0,\n",
       "  402.0,\n",
       "  5.5419455,\n",
       "  600.0,\n",
       "  100,\n",
       "  2841236401,\n",
       "  '2841236401_100_Ezreal',\n",
       "  0.0088,\n",
       "  0.0268,\n",
       "  0.03078858611111111),\n",
       " ('Leblanc',\n",
       "  298.0,\n",
       "  676.0,\n",
       "  5.5419455,\n",
       "  598.0,\n",
       "  100,\n",
       "  2841236401,\n",
       "  '2841236401_100_Leblanc',\n",
       "  0.019866666666666668,\n",
       "  0.045066666666666665,\n",
       "  0.03078858611111111)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check values from the new table\n",
    "\n",
    "conn = sqlite3.connect(database_file)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "page_size = 5\n",
    "\n",
    "rows = cursor.execute(\n",
    "    f\"SELECT * FROM {table_name} LIMIT {page_size}\").fetchall()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, epochs=50, batch_size=64, learning_rate=0.001, cutoff_loss=None):\n",
    "    device = model.device\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(\n",
    "            train_loader, desc=f'Epoch {epoch+1}/{epochs}', leave=False)\n",
    "        for X_batch, y_batch in pbar:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.set_postfix({'Loss': loss.item()})\n",
    "        current_loss = loss.item()\n",
    "        if cutoff_loss is not None and current_loss < cutoff_loss:\n",
    "            print(\n",
    "                f'Loss is below cutoff value of {cutoff_loss}. Stopping training.')\n",
    "            break\n",
    "        pbar.close()\n",
    "\n",
    "\n",
    "# Function to predict with the PyTorch model\n",
    "\n",
    "\n",
    "def predict_model(model, X, batch_size=64):\n",
    "    device = model.device\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "    dataset = torch.utils.data.TensorDataset(X_tensor)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "    predictions = []\n",
    "    pbar = tqdm(loader, desc='Predicting')\n",
    "    with torch.no_grad():\n",
    "        for X_batch, in pbar:\n",
    "            output = model(X_batch)\n",
    "            predictions.append(output.cpu().numpy())\n",
    "    return np.vstack(predictions)\n",
    "\n",
    "\n",
    "class TrajectoryPredictor(nn.Module):\n",
    "    def __init__(self, input_shape, lstm_units=128, dropout_rate=0.2, device='cpu', parameters=None):\n",
    "        super(TrajectoryPredictor, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_shape[-1], lstm_units, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.lstm2 = nn.LSTM(lstm_units, lstm_units, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(lstm_units, input_shape[-1])\n",
    "        self.device = device\n",
    "        if parameters is not None:\n",
    "            self.epochs = parameters['epochs']\n",
    "            self.batch_size = parameters['batch_size']\n",
    "            self.learning_rate = parameters['learning_rate']\n",
    "        else:\n",
    "            self.epochs = 10\n",
    "            self.batch_size = 640\n",
    "            self.learning_rate = 0.001\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc(x[:, -1, :])  # taking the output of the last time step\n",
    "        return x\n",
    "\n",
    "    def fit(self, X, y, cutoff_loss=None):\n",
    "        train_model(self, X, y, self.epochs,\n",
    "                    self.batch_size, self.learning_rate, cutoff_loss)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return predict_model(self, X, self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f'Using {device} device')\n",
    "\n",
    "data_features = [DB_columns.NORMALIZED_POS_X.value,\n",
    "                 DB_columns.NORMALIZED_POS_Z.value,\n",
    "                 DB_columns.NORMALIZED_TIME.value,]\n",
    "\n",
    "total_keys_to_fetch = 500\n",
    "\n",
    "H_values = [200]\n",
    "T_values = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_features = [\n",
    "    DB_columns.NORMALIZED_POS_X.value, DB_columns.NORMALIZED_POS_Z.value]\n",
    "\n",
    "model_getters = {\n",
    "    'linear_regression': lambda H, T: (LinearRegression(), linear_regression_features, (-1, H*len(linear_regression_features))),\n",
    "    # 'lstm': lambda H, T: (TrajectoryPredictor(\n",
    "    #     input_shape=(H, len(data_features)),\n",
    "    #     device=device,\n",
    "    #     parameters={'epochs': 10, 'batch_size': total_keys_to_fetch,\n",
    "    #                 'learning_rate': 0.001},\n",
    "    # ), data_features, (-1, H, len(data_features)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model loop:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using in-memory cache for counts\n",
      "Fetched 500 keys for offset: 0, limit: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model linear_regression with features ['normalized_pos_x', 'normalized_pos_z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model loop:  50%|█████     | 1/2 [00:06<00:06,  6.87s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model lstm with features ['normalized_pos_x', 'normalized_pos_z', 'normalized_time']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e8c7a6ebeb42808108a281b81193e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model loop:  50%|█████     | 1/2 [07:46<07:46, 466.78s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f616958e63844a97a1c61242eed895d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff55fd2ab9d420f907ba0ef35682c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a845f5d0664089ba00eaea40d84e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a025f4480dc04ab9aea910a562fe07d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef3e1ebf1df4d089caa78883087fba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0e8e4532e646be8e3cf56c6ddbe361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad23360c060e4b35bf7b63de290003ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeaf4e3a7a1c4c00bd0adb16971daadc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45573791bb14caa916e000aa99c7010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb4336034e445d3ba816471839a8fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model loop: 100%|██████████| 2/2 [03:42<00:00, 129.93s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Model loop: 100%|██████████| 2/2 [03:42<00:00, 111.47s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {(200, 10, 'linear_regression'): [0.11333388],\n",
       "             (200, 10, 'lstm'): [0.031752232]})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_models, rmse_results, absolute_errors = compare_models(\n",
    "    database_file, table_name, H_values, T_values, model_getters, data_features=data_features, total_keys_to_fetch=total_keys_to_fetch, batch_size=total_keys_to_fetch, train=True)\n",
    "\n",
    "rmse_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 10, 'linear_regression'): [0.11333388]\n",
      "(200, 10, 'lstm'): [0.031752232]\n"
     ]
    }
   ],
   "source": [
    "# Print rmse results\n",
    "\n",
    "for model_name, rmse in rmse_results.items():\n",
    "    print(f\"{model_name}: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "def plot_prediction_on_plot(plot, points, prediction, truth, map_image_path, zoom_range, options={}):\n",
    "    \"\"\"\n",
    "    Plot the player positions on the map, and overlay the predicted and true future positions.\n",
    "\n",
    "    Args:\n",
    "    plot (matplotlib.pyplot): The plot to display the map on (can be a subplot or the main plot\n",
    "    points (np.array): The player positions (x, y) at each time step\n",
    "    prediction (np.array): The predicted future player positions (x, y)\n",
    "    truth (np.array): The true future player positions (x, y)\n",
    "    map_image_path (str): The path to the map image\n",
    "    zoom_range (tuple): The x and y limits to zoom in to\n",
    "    options (dict): Additional options for the plot:\n",
    "        - figsize (tuple): The size of the plot\n",
    "        - title (str): The title of the plot\n",
    "        - inputPointsSize (int[]): Array of sizes for the input points\n",
    "        - predictionPointsSize (int[]): Array of sizes for the prediction points\n",
    "        - truthPointsSize (int[]): Array of sizes for the truth points\n",
    "        - inputPointsColor (str[]): Array of colors for the input points\n",
    "        - predictionPointsColor (str[]): Array of colors for the prediction points\n",
    "        - truthPointsColor (str[]): Array of colors for the truth points\n",
    "        - padding (int): The padding to add to the zoom range\n",
    "    \"\"\"\n",
    "    if not len(prediction) > 0 or not len(truth) > 0:\n",
    "        return\n",
    "    # Get the options\n",
    "    figsize = options.get('figsize', (10, 10))\n",
    "    title = options.get('title', 'Player positions and future predictions')\n",
    "    inputPointsSize = options.get('inputPointsSize', 2)\n",
    "    predictionPointsSize = options.get('predictionPointsSize', 2)\n",
    "    truthPointsSize = options.get('truthPointsSize', 2)\n",
    "    inputPointsColor = options.get('inputPointsColor', 'blue')\n",
    "    predictionPointsColor = options.get('predictionPointsColor', 'red')\n",
    "    truthPointsColor = options.get('truthPointsColor', 'green')\n",
    "    padding = options.get('padding', 500)\n",
    "\n",
    "    # If plot is a subplot, clear\n",
    "    if hasattr(plot, 'clear'):\n",
    "        plot.clear()\n",
    "\n",
    "    map_img = mpimg.imread(map_image_path)\n",
    "\n",
    "    # Display image scaled to the variable\n",
    "    plot.imshow(map_img, extent=[\n",
    "                zoom_range[0][0], zoom_range[0][1], zoom_range[1][0], zoom_range[1][1]])\n",
    "\n",
    "    # Overlay the player positions on the map\n",
    "    for player_sequence in points:\n",
    "        for i in range(1, len(player_sequence), 2):\n",
    "            plot.plot(player_sequence[i], player_sequence[i-1],\n",
    "                      markersize=inputPointsSize, alpha=0.6, color=inputPointsColor, marker='o')\n",
    "\n",
    "    for player in prediction:\n",
    "        plot.plot(player[1], player[0], markersize=predictionPointsSize,\n",
    "                  alpha=0.6, color=predictionPointsColor, marker='o')\n",
    "\n",
    "    for player in truth:\n",
    "        plot.plot(player[1], player[0], markersize=truthPointsSize,\n",
    "                  alpha=0.6, color=truthPointsColor, marker='o')\n",
    "\n",
    "    point_sequence_as_points = np.array([(point_sequence[i-1], point_sequence[i])\n",
    "                                        for point_sequence in points for i in range(1, len(point_sequence), 2)])\n",
    "\n",
    "    all_points = np.concatenate(\n",
    "        (point_sequence_as_points, prediction, truth))\n",
    "    # Zoom in to the center of the points\n",
    "    smallest_y = np.min(all_points[:, 0])\n",
    "    largest_y = np.max(all_points[:, 0])\n",
    "    smallest_x = np.min(all_points[:, 1])\n",
    "    largest_x = np.max(all_points[:, 1])\n",
    "\n",
    "    # Set the limits of the plot differently for plot and subplot\n",
    "    # if hasattr(plot, 'gca'):\n",
    "    #     plot = plot.gca()\n",
    "\n",
    "    plot.set_xlim(smallest_x - padding, largest_x + padding)\n",
    "    plot.set_ylim(smallest_y - padding, largest_y + padding)\n",
    "    plot.set_title(title)\n",
    "\n",
    "    # Display the plot\n",
    "    plot.set_aspect('equal')\n",
    "    plot.invert_yaxis()\n",
    "    plot.invert_xaxis()\n",
    "    plot.axis('off')\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using in-memory cache for counts\n",
      "Fetched 1 keys for offset: 0, limit: 1\n",
      "Predicting with model linear_regression\n",
      "(446, 200, 3) (446, 3)\n",
      "Model linear_regression - Sequence 0\n",
      "Predicted: [0.6910251  0.0694552  0.65604967]\n",
      "Actual: [0.6914667  0.07386667 0.33946484]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AxesSubplot' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_147290/3278215561.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Actual: {y_test}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Plot the predicted and actual values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         plot_prediction_on_plot(plt, X_test, [y_test[:2]], [\n\u001b[0m\u001b[1;32m     30\u001b[0m                                 y_pred[:2]], \"assets/2x_2dlevelminimap.png\", normalized_zoom_range)\n",
      "\u001b[0;32m/tmp/ipykernel_147290/2592074353.py\u001b[0m in \u001b[0;36mplot_prediction_on_plot\u001b[0;34m(plot, points, prediction, truth, map_image_path, zoom_range, options)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvert_xaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'AxesSubplot' object has no attribute 'show'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a prediction with each model and compare it to the actual values\n",
    "\n",
    "conn = sqlite3.connect(database_file)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "data = fetch_data_batches(cursor, table_name, \"1=1\", 0, 1, data_features)\n",
    "\n",
    "max_H = max(H_values)\n",
    "max_T = max(T_values)\n",
    "\n",
    "for (H, T, model_name), model in trained_models.items():\n",
    "    input_shape = model_getters[model_name](H, T)[2]\n",
    "    features = model_getters[model_name](H, T)[1]\n",
    "    print(f\"Predicting with model {model_name}\")\n",
    "    sequences = create_sequences_from_database_rows(data, H, T, max_H, max_T)\n",
    "    X, y = sequences\n",
    "    print(X.shape, y.shape)\n",
    "    X_test_features = X[:, :, [\n",
    "        data_features.index(feature) for feature in features]]\n",
    "    for i in range(1):\n",
    "        X_test = X_test_features[i]\n",
    "        X_test_reshaped = X_test.reshape(input_shape)\n",
    "        y_test = y[i]\n",
    "        y_pred = model.predict(X_test_reshaped)[0]\n",
    "        print(f\"Model {model_name} - Sequence {i}\")\n",
    "        print(f\"Predicted: {y_pred}\")\n",
    "        print(f\"Actual: {y_test}\")\n",
    "        # Plot the predicted and actual values\n",
    "        plot_prediction_on_plot(plt, X_test, [y_test[:2]], [\n",
    "                                y_pred[:2]], \"assets/2x_2dlevelminimap.png\", normalized_zoom_range)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
